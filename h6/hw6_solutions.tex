\documentclass[]{article}
\usepackage{listings}
\usepackage{amsmath}		% For generic math symbols
\usepackage{amssymb}		% For mathbb
\usepackage{enumerate}		% For lists indexed by letters
\usepackage{bm}				% For bold letters
\usepackage{enumitem}		% So we can resume counting problem numbers after
% interrupting with text
\usepackage{hyperref}		% For clickable URL links
\usepackage{url}			% So file names won't create hboxes
\usepackage[margin=1in]{geometry}	% Make margins wider


\setlength{\parindent}{0pt}	% Turns off indentation


% Set some useful commands
\newcommand{\half}{\frac{1}{2}}			% 1/2
\newcommand{\R}{\mathbb{R}}				% Reals symbol
\newcommand{\bbm}{\begin{bmatrix}}		% Begin bmatrix environment
\newcommand{\ebm}{\end{bmatrix}}		% End bmatrix environment
\newcommand{\x}{\bm{x}}					% Bold (vector) x
\newcommand{\y}{\bm{y}}					% Bold (vector) y
\newcommand{\z}{\bm{z}}					% Bold (vector) z
\newcommand{\A}{\bm{A}}					% Bold (matrix) A
\newcommand{\vspan}{\mathrm{span}}		% To use the word span in math mode
\newcommand{\vrange}{\mathrm{range}}		% To use the word span in math mode
\newcommand{\vdim}{\mathrm{dim}}		% To use the word span in math mode
\newcommand{\vnull}{\mathrm{null}}		% To use the word span in math mode
\newcommand{\vrank}{\mathrm{rank}}		% To use the word span in math mode
\newcommand{\vmax}{\mathrm{max}}		% To use the word span in math mode
\newcommand{\la}{\langle}				% Left angled bracket <
\newcommand{\ra}{\rangle}				% Right angled bracket >

% Place this command after each problem, before solution (examples below)
\newcommand{\solution}{\vskip 0.5cm \textbf{\large Solution:} \\}


\title{AMATH 352: Problem Set 6}
\author{Dave Moore, dmmfix@uw.edu}

\begin{document}

\maketitle
    {\Large \textbf{Due: Friday February 24, 2017}} \\

    \section*{Norms and Inner products:}
    \begin{enumerate}[resume]
	\item Let $\bm{W}$ be an invertible matrix. Show that the map
	  \[
	  \|\x\|_{\bm{W}}=\|\bm{Wx}\|_2
	  \]
	  is a norm on $\R^m$. Is it still a norm if $\bm{W}$ is singular? Why or why not?

	  \solution If $\bm{W}$ is invertible, $\|\cdot\|_{\bm{W}}$
      satisfies the 4 properties of a norm:
      \begin{enumerate}
      \item $\|\x\|_{\bm{W}} = \|\bm{Wx}\|_2 \geq 0~\forall~ \x \neq
        \bm{0}$ because $\|\cdot\|_2$ is a norm on $\R^m$, and
        $\vnull(\bm{W}) = \{\bm{0}\}$.
        
      \item Since $\bm{W}$ is invertible, $\bm{Wx} = \bm{0}
        \implies \x = \bm{0}$, so $\|\x\|_{\bm{W}}=\|\bm{Wx}\|_2 =
        \bm{0} \implies \bm{x} = \bm{0}$.
        
      \item
        \[\begin{split}
          \|\alpha \x\|_{\bm{W}} & = \|\bm{W} (\alpha \x)\|_2 \\
          & = \|\alpha \bm{Wx}\|_2 \\
          & = |\alpha| \|\bm{Wx}\|_2 \\
          & = |\alpha| \|\x\|_{\bm{W}}
        \end{split}\]

      \item By distributing the multiplication by $\bm{W}$, we see
        that all of the following statements are equivalent:
        \[\begin{split}
          \|\x + \y\|_{\bm{W}} & \leq \|\x\|_{\bm{W}} + \|\y\|_{\bm{W}} \\
          \|\bm{W}(\x + \y)\|_2 & \leq \|\bm{Wx}\|_2 + \|\bm{Wy}\|_2 \\
          \|\bm{Wx} + \bm{Wy}\|_2 & \leq \|\bm{Wx}\|_2 + \|\bm{Wy}\|_2 \\
        \end{split}\]
        We know the last version is satisfied because $\|\cdot\|_2$
        satisfies the triangle inequality.
      \end{enumerate}

      If $\bm{W}$ is singular, then $\|\cdot\|_{\bm{W}}$ is {\em not}
      a norm; by selecting a non-zero $\x \in \vnull(\bm{W})$, we can
      violate the first, second, or third properties of a norm.

	\item Consider a real square matrix $\bm{M}\in\R^{n\times
      n}$. Suppose $\bm{M}$ is symmetric and full rank. Furthermore,
      suppose $\bm{M}$ is positive definite, i.e. it satisfies
	  \[
	  \forall\x\in\R^n,~\x\neq\bm{0}\implies \x^T\bm{Mx}>0.
	  \]
	  Show that the map $\la\cdot,\cdot\ra_{\bm{M}}:\R^n\to\R$ given by
	  \[
	  \la \x,\y\ra_{\bm{M}} =\x^T\bm{My}
	  \]
	  is an inner product on $\R^n$.

	  \solution Checking the five properties of an inner product:
      \begin{enumerate}
      \item $\la \x,\x\ra_{\bm{M}} \geq 0~\forall~\x$ is true by the
        definition of a positive definite matrix.

      \item $\la \x,\x\ra_{\bm{M}} = 0 \implies \x = \bm{0}$ is also
        true because $\bm{M}$ is a square matrix of full rank,
        $\vnull(\bm{M}) = \{\bm{0}\}$.

      \item
        \[\begin{split}
        \la \alpha \x,\y\ra_{\bm{M}} &= (\alpha\x)^T\bm{My} \\
        &= \alpha(\x^T\bm{My}) \\
        &= \alpha \la \x,\y\ra_{\bm{M}}
        \end{split}\]
        
      \item
        \[\begin{split}
        \la \x,\y\ra_{\bm{M}} &= \x^T\bm{My} \\
        &= \y^T\bm{M}^T\x \\
        &= \y^T\bm{M}\x \\
        &= \la \y,\x\ra_{\bm{M}}
        \end{split}\]
        Since $\la \cdot,\cdot\ra_{\bm{M}} \in \R$, and a scalar is equal to
        it's transpose, we rewrite the expression in step 2 using the
        rule of matrix products and the transpose operator.  Since
        $\bm{M}$ is symmetric, $\bm{M}^T = \bm{M}$ in the third step.
        
      \item
        \[\begin{split}
        \la \x + \z,\y\ra_{\bm{M}} &= (\x + \z)^T\bm{My} \\
        &= \x^T\bm{My} + \z^T\bm{My} \\
        &= \la \x,\y\ra_{\bm{M}} + \la \z,\y\ra_{\bm{M}}
        \end{split}\]
      \end{enumerate}

      $\la\cdot,\cdot\ra_{\bm{M}}:\R^n\to\R$ therefore satisfies all
      five properties required of an inner product.

	\item Show that the function $\la\cdot,\cdot\ra:C^0([-1,1],\R)\to\R$ given by 
	  \[
	  \la f,g\ra = \int^1_{-1}f(x)g(x)dx
	  \]
	  is an inner product on $C^0([-1,1],\R)$. Note that $C^0([-1,1],\R)$ denotes the space of continuous functions that take input from [-1,1] and produce output in $\R$.

	  \solution Checking the five properties of an inner product:
      \begin{enumerate}
      \item $\forall~f \neq 0, \la f,f\ra \geq 0$, since the product $f(x)f(x) = f^2(x)$ is always non-negative. ($f(x) \in \R$.)

      \item From the above we know that $\la f,f\ra = 0 \implies f(x)
        = 0$, (which is the zero element for this operator) since if
        $f$ were anywhere $\neq 0$ on the interval $[-1,1]$, the
        integral would be positive.

      \item 
        \[\begin{split}
        \la \alpha f,g\ra &= \int^1_{-1}\alpha f(x)g(x)dx \\
         &= \alpha \int^1_{-1}f(x)g(x)dx \\
         &= \alpha \la f,g\ra
        \end{split}\]
        
      \item
        \[\begin{split}
        \la f,g\ra &= \int^1_{-1} f(x)g(x)dx \\
         &= \int^1_{-1}g(x)f(x)dx \\
         &= \la g,f\ra
        \end{split}\]
        
      \item
        \[\begin{split}
        \la f + h,g\ra &= \int^1_{-1} (f(x) + h(x))g(x)dx \\
        &= \int^1_{-1} (f(x)g(x) + h(x)g(x))dx \\
        &= \int^1_{-1} f(x)g(x) dx + \int^1_{-1} h(x)g(x) dx \\
        &= \la f,g\ra + \la h,g\ra 
        \end{split}\]

      \end{enumerate}

      $\la f,g \ra$ therefore satisfies all five properties required of an inner product.

    \end{enumerate}

    \section*{Conditioning:}
    \begin{enumerate}[resume]
	\item In this problem we show that orthogonal matrices are ``perfectly conditioned'' in the sense that their condition numbers with respect to the 2-norm are always 1. Suppose $\bm{O}\in\R^{n\times n}$ is an orthogonal matrix.
	  \begin{enumerate}
	  \item Show that $\|\bm{O}\|_2=1$. (Hint: recall that orthogonal matrices preserve the 2-norms of vectors).
	  \item Show that $\bm{O}^T$ is an orthogonal matrix.
	  \item Show that $\kappa_2(\bm{O})=1$.
	  \end{enumerate}

	  \solution
	  \begin{enumerate}
	  \item $\|\bm{O}\|_2 = \vmax \frac{\|\bm{O}\x\|_2}{\|\x\|_2}$, but
        since $\bm{O}$ is orthogonal, we know that $\|\bm{O}\x\|_2 =
        \|\x\|_2$ for all $\x$. So this reduces to $\|\bm{O}\|_2 = \vmax
        \frac{\|\bm{O}\x\|_2}{\|\x\|_2} = \vmax
        \frac{\|\x\|_2}{\|\x\|_2} = 1$.

	  \item By definition, an orthogonal matrix is a square matrix
        with $\bm{O}^T = \bm{O}^{-1}$. By inverting both sides, we can
        see that $(\bm{O}^T)^{-1} = \bm{O}$. Since the inverse of
        $\bm{O}^T$ is equal to its tranpose, $\bm{O}^T$ is orthogonal.

	  \item $\kappa_2(\bm{O}) = \|\bm{O}\|_2 \|\bm{O}^{-1}\|_2$, but
        by definition, $\bm{O}^{-1} = \bm{O}^T$, so this is equivalent
        to $\|\bm{O}\|_2 \|\bm{O}^T\|_2$. From the previous problems,
        we know that $\bm{O}^T$ is orthogonal and that the the 2-norm
        of any orthogonal matrix is 1. So this reduces to
        $$\kappa_2(\bm{O}) = \|\bm{O}\|_2 \|\bm{O}^T\|_2 = 1$$
	  \end{enumerate}
    \end{enumerate}

    \section*{Operation count:}
    \begin{enumerate}[resume]
	\item Find the number of necessary floating point operations required to compute the following operations (using the big-oh notation introduced in class). Explain your reasoning in each case.
	  \begin{enumerate}
	  \item Compute the sum $\A+\bm{B}$ for $\A,\bm{B}\in\R^{m\times n}$.
	  \item Compute the outer product $\bm{uv}^T$ for $\bm{u},\bm{v}\in\R^n$.
	  \item Compute the product $\A\x$ for $\x\in\R^n$ and $\A\in\R^{n\times n}$ where $\A$ is upper triangular.
	  \end{enumerate}

	  \solution
	  \begin{enumerate}
	  \item
        Each element of the sum requires a single addition, and there
        are $m \times n$ elements in $\A + \bm{B} \in \R^{m \times n}$, so
        this is O($mn$).

      \item $\bm{uv}^T \in \R^{n \times n}$, and each element of the
        product requires a single multiplication, so the total
        operation count is O($n^2$).

      \item This is equivalent to $n$ dot-products of $n$-dimensional
        vectors. Each dot-product requires $n$ multiplies and $n-1$
        additions, or $2n - 1$ total flops. So the total operation
        count is $2n^2 - n$, or O($n^2$).

        Note that because $\A$ is upper-triangular, only half of the
        operations will be with non-zero components, but the resulting
        reduction in flops of $\half$ is irrelevant for big-O.
	  \end{enumerate}


	\item \textbf{Comparing growth rates:} This exercise is meant to
      give you an idea of how quickly the number of flops required to
      solve a problem can increase when one increases the problem
      size, depending on the complexity of the algorithm
      used. Construct a table comparing $n,n\log_2(n),n^2,n^3,2^n,$
      and $n!$ for $n=2,4,8,16,64,512$. (You may need to use something
      like Wolfram Alpha to compute some of these quantities).

	  \solution
      \begin{center}
      \begin{tabular}{|r||r|r|r|r|r|r|}
        \hline
        & 2 & 4 & 8 & 16 & 64 & 512 \\
        \hline
        \hline
        $n$ & 2 & 4 & 8 & 16 & 64 & 512 \\
        \hline
        $n\log_2(n)$ & 2 & 8 & 24 & 64 & 384 & 4608 \\
        \hline
        $n^2$ & 4 & 16 & 64 & 256 & 4096 & $2.621 \times 10^{5}$ \\
        \hline
        $n^3$ & 8 & 64 & 512 & 4096 & $2.621 \times 10^{5}$ & $1.342 \times 10^{8}$ \\
        \hline
        $2^n$ & 4 & 16 & 256 & 65536 & $1.844 \times 10^{19}$ & $1.340 \times 10^{154}$ \\
        \hline
        $n!$ & 2 & 24 & 40320 & $2.092 \times 10^{13}$ & $1.268 \times 10^{89}$ & $3.477 \times 10^{1166}$ \\
        \hline
      \end{tabular}
      \end{center}
    \end{enumerate}

\end{document}
