\documentclass[]{article}
\usepackage{amsmath}		% For generic math symbols
\usepackage{amssymb}		% For mathbb
\usepackage{enumerate}		% For lists indexed by letters
\usepackage{bm}				% For bold letters
\usepackage{enumitem}		% So we can resume counting problem numbers after
% interrupting with text
\usepackage{hyperref}		% For clickable URL links
\usepackage{url}			% So file names won't create hboxes

\setlength{\parindent}{0pt}	% Turns off indentation


% Set some useful commands
\newcommand{\half}{\frac{1}{2}}			% 1/2
\newcommand{\R}{\mathbb{R}}				% Reals symbol
\newcommand{\bbm}{\begin{bmatrix}}		% Begin bmatrix environment
\newcommand{\ebm}{\end{bmatrix}}		% End bmatrix environment
\newcommand{\x}{\bm{x}}					% Bold (vector) x
\newcommand{\y}{\bm{y}}					% Bold (vector) y
\newcommand{\A}{\bm{A}}					% Bold (matrix) A
\newcommand{\I}{\bm{I}}					% Bold (matrix) I
\newcommand{\vspan}{\mathrm{span}}		% To use the word span in math mode
\newcommand{\vrange}{\mathrm{range}}		% To use the word span in math mode
\newcommand{\vdim}{\mathrm{dim}}		% To use the word span in math mode
\newcommand{\vnull}{\mathrm{null}}		% To use the word span in math mode
\newcommand{\vrank}{\mathrm{rank}}		% To use the word span in math mode

% Place this command after each problem, before solution (examples below)
\newcommand{\solution}{\vskip 0.5cm \textbf{\large Solution:} \\}


\title{AMATH 352: Problem Set 5}
\author{Dave Moore, dmmfix@uw.edu}

\begin{document}

\maketitle
    {\Large \textbf{Due: Friday February 17, 2017}} \\


    \section*{Matrices:}
    \begin{enumerate}
	\item Consider a real matrix $\A\in\R^{m\times n}$ with $m\geq n$ which is full rank, i.e. $\vrank(\A) = n$.
	  \begin{enumerate}
	  \item Find the nullspace of $\A$.
	  \item Show that for any vector $\x\in\R^n,~\x^T\A^T\A\x=\|\A\x\|^2_2$.
      \item Show that the matrix $\A^T\A$ is invertible. Hint: show the nullspace of $\A^T\A$ is $\{\bm{0}\}$ by assuming $\bm{z}\in\mathrm{null}(\A^T\A)$ then using the previous parts of this question to show that $\bm{z}=\bm{0}$. (Second hint: try multiplying by $\bm{z}^T$. You will also need one of the defining properties of a norm).
	  \end{enumerate}

	  \solution
	  \begin{enumerate}

      \item By rank-nullity, $\vrank(A) + \vdim(\vnull(\A)) = n$, so
        the dimension of the nullspace is 0 which implies $\vnull(\A)
        = \{\bm{0}\}$.

	  \item From the properties of the tranpose operator, we can
        express $\x^T\A^T\A\x$ as $(\A\x)^T\A x$. In other words, it
        is the inner product of $\A\x$ with itself. But we already
        know that the inner product of vector with itself is
        equivalent to the square of the 2-norm, so
        $$\x^T\A^T\A\x = (\A\x)^T\A \x = \A \x \cdot \A \x = \|\A\x\|^2_2$$

      \item From the previous answer, we know that if we create the
        product $\x^T(\A^T\A)\x$ with some arbitrary $\x \in \R^n$,
        that it is equivalent to $\|\A \x\|_2^2$. Assume $\x \in
        \vnull(\A^T\A)$. Then
        $$\x^T(\A^T\A)\x = \x^T\bm{0} = 0$$ But this means that $\|\A
        \x\|_2^2 = 0$, which implies that $\A \x = \bm{0}$ by the
        properties of the 2-norm. Since we know that $\A$ is
        full-rank, $\A \x = \bm{0} \implies \x = \bm{0}$. Therefore
        $\vnull(\A^T\A) = \{ \bm{0} \}$, which shows that $\A^T\A$ is
        invertible, since it is a square matrix of full rank.
        
	  \end{enumerate}
	  
	\item Suppose $\A\in\R^{n\times n}$ is invertible. Find the inverse of $\A^T\A$ and show that it is symmetric.

	  \solution
	  Using the associative property of matrix multiplication, we can see that the inverse of $\A^T\A$ is $\A^{-1}(\A^T)^{-1}$ since
      \[
      \A^T \A \A^{-1}(\A^T)^{-1} = \A^T \I (\A^T)^{-1} = \I
      \]
      But the properties of the matrix inverse allows us to express
      $(\A^T)^{-1}$ as $(\A^{-1})^T$, so the inverse is equivalently
      $\A^{-1}(\A^{-1})^T$, in other words, it's the product of a matrix
      with its transpose. Any such matrix product must be symmetric,
      since for $\bm{C} = \bm{B}\bm{B}^T$,
      \[
      \bm{C}_{ij} = \sum_{k=1}^{m} \bm{B}_{ik} \bm{B}^T_{kj}
      \]
      but $\bm{B}^T_{kj} = \bm{B}_{jk}$ so
      \[
      \bm{C}_{ij} = \sum_{k=1}^{m} \bm{B}_{ik} \bm{B}_{jk} = \sum_{k=1}^{m} \bm{B}_{jk} \bm{B}_{ik} = \bm{C}_{ji}
      \]


	\item Suppose $\A,\bm{B}\in\R^{n\times n}$. Show that $\bm{AB}$ is invertible if and only if both $\A$ and $\bm{B}$ are invertible. This means you must show that if $\bm{AB}$ is invertible, so are $\A$ and $\bm{B}$ and you must also show that if $\A$ and $\bm{B}$ are invertible, so is $\bm{AB}$. Hint: use the determinant.

	  \solution

      The statement that $\A\bm{B}$ is invertible is equivalent to
      stating that its determinant is non-zero. By the properties of
      the determinant, we know that $$det(\A \bm{B}) = det(\A)
      \det(\bm{B})$$ so if $det(\A\bm{B}) \neq 0$, then both $\A$ and
      $\bm{B}$ must have non-zero determinants, and are therefore
      invertible. If either of $\A$ or $\bm{B}$ are non-invertible,
      then it follows that $det(\A\bm{B}) = 0$, and $\A\bm{B}$ is
      non-invertible.

	\item Suppose $\A,\bm{B},\bm{C}\in\R^{n\times n}$ are all invertible. Show that $\bm{ABC}$ is invertible by finding a matrix $\bm{D}$ such that $(\bm{ABC})\bm{D}=\bm{D}(\bm{ABC})=\bm{I}$.

	  \solution

      $\bm{D} = \bm{C}^{-1} \bm{B}^{-1} \A^{-1}$ satisfies the
      requirement, since the associative property of matrix
      multiplication shows that
      $$ \bm{ABC}\bm{C}^{-1} \bm{B}^{-1} \A^{-1} = \bm{ABI} \bm{B}^{-1} \A^{-1} = \bm{AI} \A^{-1} = \I $$
      and
      $$ \bm{C}^{-1} \bm{B}^{-1} \A^{-1} \bm{ABC} = \bm{C}^{-1} \bm{B}^{-1} \bm{IBC} = \bm{C}^{-1} \bm{IC} = \I $$
      
	\item Based on your answer to the previous problem, what do you think the inverse of $\A_1\A_2\cdots \A_k$ would be, assuming $\A_1,\A_2,\dots,\A_k\in\R^{n\times n}$ are all invertible? You do not have to provide a proof, but you should briefly explain your reasoning.

	  \solution

      If we define $\A = \prod_{k=1}^{n} \A_k$, then $\A^{-1} =
      \prod_{k=n}^{1} \A_k^{-1}$, that is, we multiply the inverses in
      reverse order. This allows associative cancellation under either
      left- or right-multiplication by $\A^{-1}$.


	\item Let $\A\in\R^{n\times n}$ be invertible and let $\bm{B}\in\R^{n\times r}$ for some positive integer $r$. Show that $\bm{AX}=\bm{B}$ has a unique solution. Note that $\bm{X}\in\R^{n\times r}$ is a matrix.

	  \solution Assume that there were two solutions, $\A\bm{X}_1 =
      \bm{B}$ and $\A\bm{X}_2 = \bm{B}$. Then we can see by equating
      them, and subtracting, that the columns of $\bm{X}_1 - \bm{X}_2$
      must be in the null space of $\A$.
      \[
      \begin{split}
        \A\bm{X}_1 & = \A\bm{X}_2 \\
        \A\bm{X}_1 - \A\bm{X}_2 &= \bm{0}\\
        \A(\bm{X}_1 - \bm{X}_2) &= \bm{0}
      \end{split}
      \]
      
      Since $\A$ is invertible, it has no non-trival null space. So it
      must be the case that $\bm{X}_1 = \bm{X}_2$ and only a
      unique solution is possible. Therefore
      \[
      \begin{split}
        \A^{-1}\A\bm{X} &= \A^{-1}\bm{B} \\
        \bm{X} &= \A^{-1}\bm{B}
      \end{split}
      \]
      uniquely solves the system of equations.


	\item We saw in class that multiplication by an orthogonal matrix
      preserves lengths (with respect to the 2-norm). In this problem
      you will show that they also preserve the dot product and
      orthogonality, that is, the dot product between two vectors is
      the same as the dot product of any orthogonal matrix applied to
      the two vectors.

	  Let $\bm{U}\in\R^{n\times n}$ be an orthogonal matrix. Show that for any $\x,\y\in\R^n$
	  \begin{enumerate}
	  \item $(\bm{Ux})\cdot(\bm{Uy})=\x\cdot\y$,
	  \item $(\bm{Ux})\cdot(\bm{Uy}) = 0$ if and only if $\x\cdot \y=0$.

		(This means you must show that $(\bm{Ux})\cdot(\bm{Uy}) = 0$ implies $\x\cdot \y=0$ and that $\x\cdot \y=0$ implies $(\bm{Ux})\cdot(\bm{Uy}) = 0$).
	  \end{enumerate}

	  \solution
	  \begin{enumerate}
	  \item Recall that the dot product is distributive, so that
        $$\x \cdot (\y + \bm{z}) = \x \cdot \y +
        \x \cdot \bm{z}$$ If we denote the columns of $\bm{U}$ as
        $\bm{U}_i$, then we can rewrite the matrix-vector product
        $\bm{U}\x$ as $\sum_{i} \bm{U}_i x_i$. This allows us to
        rewrite 
        \[\begin{split}
        (\bm{Ux})\cdot(\bm{Uy}) &= \left(\sum_{i} \bm{U}_i x_i\right) \cdot \left(\sum_{j} \bm{U}_j y_j\right) \\
        &= \sum_{i} \sum_{j} (\bm{U}_i x_i) \cdot (\bm{U}_j y_j) \\
        &= \sum_{i} \sum_{j} x_i y_j (\bm{U}_i \cdot \bm{U}_j)
        \end{split}\]
        However, because $\bm{U}$ is orthogonal, we know that
        $\bm{U}_i \cdot \bm{U}_j$ is only non-zero when $i = j$, and
        further, that when $i = j$, $\bm{U}_i \cdot \bm{U}_j = 1$. So
        all of the summation terms except $i = j$ drop out, leaving us
        with
        \[\begin{split}
        (\bm{Ux})\cdot(\bm{Uy}) &= \sum_{i} \sum_{j} x_i y_j (\bm{U}_i \cdot \bm{U}_j) \\
        &= \sum_{i} x_i y_i (\bm{U}_i \cdot \bm{U}_i) \\
        &= \sum_{i}  x_i y_i \\
        &= \x \cdot \y
        \end{split}\]

      \item Since we demonstrated the full equality in the previous
        step, there's nothing remaining to show here. Since
        $(\bm{Ux})\cdot(\bm{Uy}) = \x \cdot \y$, both
        \[\begin{split}
        (\bm{Ux})\cdot(\bm{Uy}) = 0 & \implies \x \cdot \y = 0 \\ 
        \x \cdot \y = 0 & \implies (\bm{Ux})\cdot(\bm{Uy}) = 0
        \end{split}\]
        are true.
	  \end{enumerate}
    \end{enumerate}

    \section*{Systems of equations}
    \begin{enumerate}[resume]
	\item \begin{figure}
	  \centering
	  \begin{tabular}{ccccc}
		Nutrient & Food 1 & Food 2 & Food 3 & Total nutrients required (mg) \\ \hline
		Vitamin C & 10 & 20 & 20 & 100 \\
		Calcium & 50 & 40 & 10 & 300 \\
		Magnesium & 30 & 10 & 40 & 200 \\ \hline
	  \end{tabular}
	  \caption{Milligrams (mg) of nutrients per unit of food}
	  \label{fig:diet}
	\end{figure}

	  A dietician is planning a meal that supplies certain quantities of vitamin C, calcium, and magnesium. Three foods will be included in the diet, their quantities measured in appropriate units. The nutrients supplied by these foods and the dietary requirements are given in Figure \ref{fig:diet}. Write a linear system of equations which represents the problem of choosing the appropriate amounts of each food that should be consumed to get the desired nutrients. Write the linear system of equations as a matrix-vector equation.

	  \solution We will denote the vector of supplied foods as $\x
      \in \R^3$, where $x_i$ represents the amount of Food $i$. As a
      system of equations, we are looking for solutions to
      \[\begin{split}
      10 x_1 + 20 x_2 + 20 x_3 &= 100 \\
      50 x_1 + 40 x_2 + 10 x_3 &= 300 \\
      30 x_1 + 10 x_2 + 10 x_3 &= 200
      \end{split}\]
      or as a matrix-vector equation, we are looking for solutions to $\A \x = \bm{b}$ for
      $$ \A = \bbm 10 & 20 & 20 \\ 50 & 40 & 10 \\ 30 & 10 & 10 \ebm, \bm{b} = \bbm 100 \\ 300 \\ 200 \ebm $$

	\item For each of the following matrices, $\A$, and vectors, $\bm{b}$, determine the number of solutions to $\A\x=\bm{b}$.
	  \begin{enumerate}
	  \item $\A = \bbm 1&1\\1&1 \ebm,\quad \bm{b}=\bbm 1\\2\ebm$
	  \item $\A = \bbm 1&1\\1&-1\ebm,\quad \bm{b}=\bbm 1\\2\ebm$
	  \item $\A = \bbm 1 & 2 & 1 \\ 1&1&0\\1&2&0 \ebm,\quad \bm{b}=\bbm 4\\2\\3 \ebm$
	  \item $\A = \bbm 1&0&1\\0&1&1\\1&0&1 \ebm,\quad \bm{b}=\bbm 2\\2\\1 \ebm$
	  \item $\A = \bbm 1&0&1\\0&1&1\\1&0&1 \ebm,\quad \bm{b}=\bbm 5\\-3\\5 \ebm$
	  \end{enumerate}

	  \solution
	  \begin{enumerate}
	  \item By inspection, $\vrange(\A) = \vspan\left(\bbm 1 \\ 1 \ebm\right)$ since
        it's columns are identical. Since $\bbm 1 \\ 2 \ebm$ is not a
        scalar multiple of $\bbm 1 \\ 1 \ebm$, $\bm{b} \not\in
        \vrange(\A)$, and there are no solutions.

      \item $\A \in \R^{2x2}$ and is full rank, since its columns are
        non-zero and not scalar multiples. So $\vrange(\A) = \R^{2}$,
        and $\vdim(\vnull(\A)) = 0$, which means there is a single valid
        solution for this equation.

      \item Recalling that for $\A \in \R^{nxn}$, $det(\A) \neq 0$
        implies that $\A$ has full rank and a trivial nullspace, here
        we see that $det(\A) = 1$, which means this equation has a
        single valid solution.

	  \item By inspection, $\A$ does not have full rank, since
        $$ \bbm 1\\0\\1 \ebm + \bbm 0\\1\\0 \ebm - \bbm 1\\1\\1 \ebm =
        \bm{0} $$ Since the first two columns {\em are} linearly
        independent (no scalar multiple of the first column will have
        a non-zero second component), we need to determine if there
        are solutions to
        $$ \alpha \bbm 1\\0\\1 \ebm + \beta \bbm 0\\1\\0 \ebm = \bbm
        2\\2\\1 \ebm $$ However, by examining the first and third
        component of the sum, we see that $\alpha = 2$ {\em and}
        $\alpha = 1$ are required to satisfy the equation, so $\bm{b}
        \not\in \vrange(\A)$, and there are zero solutions.
        
	  \item Noting that $\A$ has the same properties as in the
        previous problem, we are looking for solutions to
        $$ \alpha \bbm 1\\0\\1 \ebm + \beta \bbm 0\\1\\0 \ebm = \bbm
        5\\-3\\5 \ebm $$ which we can simply observe is satisfied by
        $\alpha = 5,~\beta = -3$. Since $\vdim(\vnull(\A)) = 1$ by the
        rank-nullity theorem, and $\bm{b} \in \vrange(\A)$, there are
        infinitely many solutions to $\A\x = \bm{b}$ as given in
        this problem.
	  \end{enumerate}
    \end{enumerate}

\end{document}
